# LinkedIn Post Generator Environment Configuration
# Copy this file to .env and update the values according to your setup

# ===========================================
# API Configuration
# ===========================================

# Base URL for the AI model API
# For OpenAI: https://api.openai.com/v1
# For local Ollama: http://localhost:11434 or http://ollama:11434 (if using Docker)
# For other providers: your_provider_url
BASE_URL=https://api.openai.com/v1

# API Key for authentication
# Get this from your AI model provider (OpenAI, Anthropic, etc.)
# For local models like Ollama, this can be empty or any value
API_KEY=your_api_key_here

# Model name to use
# OpenAI examples: gpt-4o-mini, gpt-4o, gpt-3.5-turbo
# Local Ollama examples: llama2, mistral, codellama, gemma, phi3
MODEL_NAME=gpt-4o-mini

# ===========================================
# Docker Configuration (Optional)
# ===========================================

# Uncomment and modify if you want to use different ports
# BACKEND_PORT=8000
# FRONTEND_PORT=80

# ===========================================
# Development vs Production
# ===========================================

# Set to 'development' for local development, 'production' for Docker
ENVIRONMENT=production

# ===========================================
# Example Configurations
# ===========================================

# Example 1: OpenAI Configuration
# BASE_URL=https://api.openai.com/v1
# API_KEY=sk-your-openai-api-key-here
# MODEL_NAME=gpt-4o-mini

# Example 2: Local Ollama Configuration
# BASE_URL=http://localhost:11434
# API_KEY=ollama
# MODEL_NAME=llama2

# Example 3: Docker with Ollama service
# BASE_URL=http://ollama:11434
# API_KEY=ollama
# MODEL_NAME=mistral
